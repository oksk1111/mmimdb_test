{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbf95b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oksk1\\workspace\\mmimdb_test\\.venv\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtimm\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# MM-IMDb ë©€í‹°ëª¨ë‹¬ ì˜í™” ì¥ë¥´ ì˜ˆì¸¡ ëª¨ë¸ ë¹„êµ ì‹¤í—˜\n",
    "# Multi-Modal Movie Genre Prediction Model Comparison on MM-IMDb Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b19aeb",
   "metadata": {},
   "source": [
    "# ğŸ“‘ MM-IMDb ë©€í‹°ëª¨ë‹¬ ì˜í™” ì¥ë¥´ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ ë° ë¹„êµ ì‹¤í—˜\n",
    "\n",
    "## ğŸ¯ ì—°êµ¬ ëª©í‘œ\n",
    "- **ì£¼ì œ**: ë©€í‹°ëª¨ë‹¬ ìœµí•© ê¸°ë°˜ ì˜í™” ì¥ë¥´ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ\n",
    "- **ë°ì´í„°ì…‹**: MM-IMDb (25,000í¸ ì˜í™”, í¬ìŠ¤í„° ì´ë¯¸ì§€ + ì¤„ê±°ë¦¬ í…ìŠ¤íŠ¸ + 23ê°œ ë©€í‹°ë¼ë²¨ ì¥ë¥´)\n",
    "- **í•µì‹¬ ê¸°ì—¬**: Cross-Attention ê¸°ë°˜ ìœµí•© ëª¨ë¸ ì œì•ˆìœ¼ë¡œ ì´ë¯¸ì§€Â·í…ìŠ¤íŠ¸ ê°„ ìƒí˜¸ì‘ìš© ì •êµí™”\n",
    "\n",
    "## ğŸ”¬ ì‹¤í—˜ êµ¬ì„±\n",
    "### ë¹„êµ ëª¨ë¸êµ°\n",
    "1. **í…ìŠ¤íŠ¸ ë‹¨ì¼ ëª¨ë‹¬**: BERT, RoBERTa\n",
    "2. **ì´ë¯¸ì§€ ë‹¨ì¼ ëª¨ë‹¬**: ResNet50, Vision Transformer (ViT)\n",
    "3. **ê°ì²´ íƒì§€ ê¸°ë°˜**: YOLO, Faster R-CNN\n",
    "4. **ë©€í‹°ëª¨ë‹¬ ìœµí•©**: Early Fusion, Late Fusion, Attention Fusion\n",
    "5. **ì œì•ˆ ëª¨ë¸**: Cross-Attention Fusion\n",
    "\n",
    "### í‰ê°€ ì§€í‘œ\n",
    "- Accuracy, Precision, Recall, F1-score, ROC-AUC, mAP\n",
    "\n",
    "### ì„¤ëª…ê°€ëŠ¥ì„± (XAI)\n",
    "- Grad-CAM (ì´ë¯¸ì§€), Attention Map (í…ìŠ¤íŠ¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63654d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ë°ì´í„°ì…‹ ì„¤ì • ë° êµ¬ì„±\n",
    "# MM-IMDb Dataset Configuration\n",
    "\n",
    "# ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "DATASET_PATH = \"data/mmimdb\"  # MM-IMDb ë°ì´í„°ì…‹ ê²½ë¡œ\n",
    "IMAGE_PATH = os.path.join(DATASET_PATH, \"images\")\n",
    "METADATA_PATH = os.path.join(DATASET_PATH, \"dataset.json\")\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì •\n",
    "IMAGE_SIZE = 224\n",
    "MAX_TEXT_LENGTH = 512\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_GENRES = 23  # MM-IMDb ì¥ë¥´ ìˆ˜\n",
    "\n",
    "# ì¥ë¥´ ë¼ë²¨ ì •ì˜ (MM-IMDb 23ê°œ ì¥ë¥´)\n",
    "GENRE_LABELS = [\n",
    "    'Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "    'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Musical', 'Mystery',\n",
    "    'News', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western'\n",
    "]\n",
    "\n",
    "print(f\"Dataset configuration:\")\n",
    "print(f\"- Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"- Max text length: {MAX_TEXT_LENGTH}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Number of genres: {NUM_GENRES}\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"- Number of epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ae857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬ ì„¤ì •\n",
    "# Data Preprocessing Setup\n",
    "\n",
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜ (ë°ì´í„° ì¦ê°• í¬í•¨)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "print(\"ë°ì´í„° ì „ì²˜ë¦¬ ì„¤ì • ì™„ë£Œ:\")\n",
    "print(f\"- ì´ë¯¸ì§€ ë³€í™˜: í¬ê¸° ì¡°ì •, ì •ê·œí™”, ë°ì´í„° ì¦ê°•\")\n",
    "print(f\"- í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì €: BERT, RoBERTa\")\n",
    "print(f\"- ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´: {MAX_TEXT_LENGTH} í† í°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051cbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. MM-IMDb ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "# Custom Dataset Class for MM-IMDb\n",
    "\n",
    "class MMIMDbDataset(Dataset):\n",
    "    def __init__(self, metadata_file, image_dir, tokenizer, transform=None, max_length=512):\n",
    "        \"\"\"\n",
    "        MM-IMDb ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
    "        Args:\n",
    "            metadata_file: ë©”íƒ€ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ\n",
    "            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "            tokenizer: í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì €\n",
    "            transform: ì´ë¯¸ì§€ ë³€í™˜\n",
    "            max_length: í…ìŠ¤íŠ¸ ìµœëŒ€ ê¸¸ì´\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "        with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.genre_to_idx = {genre: idx for idx, genre in enumerate(GENRE_LABELS)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        image_path = os.path.join(self.image_dir, item['image'])\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except:\n",
    "            # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ì‹œ ë¹ˆ ì´ë¯¸ì§€ ìƒì„±\n",
    "            image = torch.zeros(3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•\n",
    "        plot = item.get('plot', '')\n",
    "        if isinstance(plot, list):\n",
    "            plot = ' '.join(plot)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            plot,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # ì¥ë¥´ ë¼ë²¨ (ë©€í‹°ë¼ë²¨)\n",
    "        genres = item.get('genres', [])\n",
    "        label = torch.zeros(NUM_GENRES)\n",
    "        for genre in genres:\n",
    "            if genre in self.genre_to_idx:\n",
    "                label[self.genre_to_idx[genre]] = 1.0\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': label,\n",
    "            'text': plot\n",
    "        }\n",
    "\n",
    "print(\"MM-IMDb ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbac778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ë‹¨ì¼ ëª¨ë‹¬ ëª¨ë¸ ì •ì˜\n",
    "# Single Modality Models\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    \"\"\"BERT ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.classifier(output)\n",
    "\n",
    "class RoBERTaClassifier(nn.Module):\n",
    "    \"\"\"RoBERTa ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3):\n",
    "        super(RoBERTaClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.classifier(output)\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    \"\"\"ResNet50 ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = timm.create_model('resnet50', pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()  # ë§ˆì§€ë§‰ ì¸µ ì œê±°\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.resnet(images)\n",
    "        output = self.dropout(features)\n",
    "        return self.classifier(output)\n",
    "\n",
    "class ViTClassifier(nn.Module):\n",
    "    \"\"\"Vision Transformer ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        self.vit.head = nn.Identity()  # ë§ˆì§€ë§‰ ì¸µ ì œê±°\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(768, num_classes)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.vit(images)\n",
    "        output = self.dropout(features)\n",
    "        return self.classifier(output)\n",
    "\n",
    "print(\"ë‹¨ì¼ ëª¨ë‹¬ ëª¨ë¸ ì •ì˜ ì™„ë£Œ:\")\n",
    "print(\"- BERT í…ìŠ¤íŠ¸ ë¶„ë¥˜ê¸°\")\n",
    "print(\"- RoBERTa í…ìŠ¤íŠ¸ ë¶„ë¥˜ê¸°\") \n",
    "print(\"- ResNet50 ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°\")\n",
    "print(\"- Vision Transformer ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ë©€í‹°ëª¨ë‹¬ ìœµí•© ëª¨ë¸ ì •ì˜\n",
    "# Multimodal Fusion Models\n",
    "\n",
    "class EarlyFusionModel(nn.Module):\n",
    "    \"\"\"Early Fusion: íŠ¹ì§•ì„ ì´ˆê¸°ì— ê²°í•©\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3):\n",
    "        super(EarlyFusionModel, self).__init__()\n",
    "        # í…ìŠ¤íŠ¸ ì¸ì½”ë”\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # ì´ë¯¸ì§€ ì¸ì½”ë”\n",
    "        self.resnet = timm.create_model('resnet50', pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # ìœµí•© ì¸µ\n",
    "        self.fusion_dim = self.bert.config.hidden_size + 2048\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.fusion_dim, num_classes)\n",
    "        \n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ\n",
    "        text_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "        \n",
    "        # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ\n",
    "        image_features = self.resnet(images)\n",
    "        \n",
    "        # íŠ¹ì§• ê²°í•©\n",
    "        fused_features = torch.cat([text_features, image_features], dim=1)\n",
    "        output = self.dropout(fused_features)\n",
    "        return self.classifier(output)\n",
    "\n",
    "class LateFusionModel(nn.Module):\n",
    "    \"\"\"Late Fusion: ê° ëª¨ë‹¬ë¦¬í‹°ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµ í›„ ê²°ê³¼ ê²°í•©\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3):\n",
    "        super(LateFusionModel, self).__init__()\n",
    "        # í…ìŠ¤íŠ¸ ë¶„ë¥˜ê¸°\n",
    "        self.text_classifier = BERTClassifier(num_classes, dropout)\n",
    "        # ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°\n",
    "        self.image_classifier = ResNetClassifier(num_classes, dropout)\n",
    "        \n",
    "        # ìœµí•© ê°€ì¤‘ì¹˜\n",
    "        self.fusion_weights = nn.Parameter(torch.tensor([0.5, 0.5]))\n",
    "        \n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # ê° ëª¨ë‹¬ë¦¬í‹°ë³„ ì˜ˆì¸¡\n",
    "        text_logits = self.text_classifier(input_ids, attention_mask)\n",
    "        image_logits = self.image_classifier(images)\n",
    "        \n",
    "        # ê°€ì¤‘ í‰ê· \n",
    "        weights = torch.softmax(self.fusion_weights, dim=0)\n",
    "        fused_logits = weights[0] * text_logits + weights[1] * image_logits\n",
    "        return fused_logits\n",
    "\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    \"\"\"Attention Fusion: ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ëª¨ë‹¬ë¦¬í‹° ì¤‘ìš”ë„ ê²°ì •\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3):\n",
    "        super(AttentionFusionModel, self).__init__()\n",
    "        # íŠ¹ì§• ì¶”ì¶œê¸°\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.resnet = timm.create_model('resnet50', pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜\n",
    "        self.text_attention = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.image_attention = nn.Linear(2048, 1)\n",
    "        \n",
    "        # ë¶„ë¥˜ê¸°\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + 2048, num_classes)\n",
    "        \n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # íŠ¹ì§• ì¶”ì¶œ\n",
    "        text_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "        image_features = self.resnet(images)\n",
    "        \n",
    "        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "        text_att = torch.sigmoid(self.text_attention(text_features))\n",
    "        image_att = torch.sigmoid(self.image_attention(image_features))\n",
    "        \n",
    "        # ì–´í…ì…˜ ì ìš©\n",
    "        weighted_text = text_att * text_features\n",
    "        weighted_image = image_att * image_features\n",
    "        \n",
    "        # íŠ¹ì§• ê²°í•©\n",
    "        fused_features = torch.cat([weighted_text, weighted_image], dim=1)\n",
    "        output = self.dropout(fused_features)\n",
    "        return self.classifier(output)\n",
    "\n",
    "class CrossAttentionFusionModel(nn.Module):\n",
    "    \"\"\"Cross-Attention Fusion: ì œì•ˆí•˜ëŠ” ëª¨ë¸\"\"\"\n",
    "    def __init__(self, num_classes=NUM_GENRES, dropout=0.3, d_model=512):\n",
    "        super(CrossAttentionFusionModel, self).__init__()\n",
    "        # íŠ¹ì§• ì¶”ì¶œê¸°\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.resnet = timm.create_model('resnet50', pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # ì°¨ì› ì •ë ¬\n",
    "        self.text_proj = nn.Linear(self.bert.config.hidden_size, d_model)\n",
    "        self.image_proj = nn.Linear(2048, d_model)\n",
    "        \n",
    "        # Cross-Attention ì¸µ\n",
    "        self.cross_attention = nn.MultiheadAttention(d_model, num_heads=8, dropout=dropout)\n",
    "        \n",
    "        # ë¶„ë¥˜ê¸°\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(d_model * 2, num_classes)\n",
    "        \n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # íŠ¹ì§• ì¶”ì¶œ\n",
    "        text_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.pooler_output\n",
    "        image_features = self.resnet(images)\n",
    "        \n",
    "        # ì°¨ì› ì •ë ¬\n",
    "        text_proj = self.text_proj(text_features).unsqueeze(0)  # [1, batch, d_model]\n",
    "        image_proj = self.image_proj(image_features).unsqueeze(0)  # [1, batch, d_model]\n",
    "        \n",
    "        # Cross-Attention\n",
    "        text_attended, _ = self.cross_attention(text_proj, image_proj, image_proj)\n",
    "        image_attended, _ = self.cross_attention(image_proj, text_proj, text_proj)\n",
    "        \n",
    "        # íŠ¹ì§• ê²°í•©\n",
    "        fused_features = torch.cat([\n",
    "            text_attended.squeeze(0), \n",
    "            image_attended.squeeze(0)\n",
    "        ], dim=1)\n",
    "        \n",
    "        output = self.dropout(fused_features)\n",
    "        return self.classifier(output)\n",
    "\n",
    "print(\"ë©€í‹°ëª¨ë‹¬ ìœµí•© ëª¨ë¸ ì •ì˜ ì™„ë£Œ:\")\n",
    "print(\"- Early Fusion Model\")\n",
    "print(\"- Late Fusion Model\")\n",
    "print(\"- Attention Fusion Model\")\n",
    "print(\"- Cross-Attention Fusion Model (ì œì•ˆ ëª¨ë¸)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75245d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
    "# Training and Evaluation Functions\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE):\n",
    "    \"\"\"ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜\"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
    "    criterion = nn.BCEWithLogitsLoss()  # ë©€í‹°ë¼ë²¨ ë¶„ë¥˜\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # í•™ìŠµ ë‹¨ê³„\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Training')\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # ëª¨ë¸ ìœ í˜•ì— ë”°ë¥¸ ìˆœì „íŒŒ\n",
    "            if isinstance(model, (BERTClassifier, RoBERTaClassifier)):\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "            elif isinstance(model, (ResNetClassifier, ViTClassifier)):\n",
    "                outputs = model(images)\n",
    "            else:  # ë©€í‹°ëª¨ë‹¬ ëª¨ë¸\n",
    "                outputs = model(images, input_ids, attention_mask)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({'Loss': loss.item()})\n",
    "        \n",
    "        # ê²€ì¦ ë‹¨ê³„\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                if isinstance(model, (BERTClassifier, RoBERTaClassifier)):\n",
    "                    outputs = model(input_ids, attention_mask)\n",
    "                elif isinstance(model, (ResNetClassifier, ViTClassifier)):\n",
    "                    outputs = model(images)\n",
    "                else:\n",
    "                    outputs = model(images, input_ids, attention_mask)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}')\n",
    "        \n",
    "        # í•™ìŠµë¥  ì¡°ì •\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # ìµœì  ëª¨ë¸ ì €ì¥\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f'best_model_{type(model).__name__}.pth')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def evaluate_model(model, test_loader, model_name=\"Model\"):\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€ í•¨ìˆ˜\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f'Evaluating {model_name}'):\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            if isinstance(model, (BERTClassifier, RoBERTaClassifier)):\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "            elif isinstance(model, (ResNetClassifier, ViTClassifier)):\n",
    "                outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images, input_ids, attention_mask)\n",
    "            \n",
    "            # ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”ë¡œ í™•ë¥  ê³„ì‚°\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = (probabilities > 0.5).float()\n",
    "            \n",
    "            all_predictions.append(predictions.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_probabilities.append(probabilities.cpu())\n",
    "    \n",
    "    # ê²°ê³¼ ê²°í•©\n",
    "    all_predictions = torch.cat(all_predictions, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "    all_probabilities = torch.cat(all_probabilities, dim=0).numpy()\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    metrics = calculate_metrics(all_labels, all_predictions, all_probabilities)\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # ì „ì²´ ì •í™•ë„ (Exact Match)\n",
    "    exact_match = np.mean(np.all(y_true == y_pred, axis=1))\n",
    "    metrics['Exact_Match_Accuracy'] = exact_match\n",
    "    \n",
    "    # ë¼ë²¨ë³„ ì •í™•ë„\n",
    "    label_accuracy = np.mean(y_true == y_pred)\n",
    "    metrics['Label_Accuracy'] = label_accuracy\n",
    "    \n",
    "    # Precision, Recall, F1-score (Macro)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics['Macro_Precision'] = precision\n",
    "    metrics['Macro_Recall'] = recall\n",
    "    metrics['Macro_F1'] = f1\n",
    "    \n",
    "    # Precision, Recall, F1-score (Micro)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)\n",
    "    metrics['Micro_Precision'] = precision_micro\n",
    "    metrics['Micro_Recall'] = recall_micro\n",
    "    metrics['Micro_F1'] = f1_micro\n",
    "    \n",
    "    # ROC-AUC (Macro)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_prob, average='macro')\n",
    "        metrics['ROC_AUC_Macro'] = roc_auc\n",
    "    except ValueError:\n",
    "        metrics['ROC_AUC_Macro'] = 0.0\n",
    "    \n",
    "    # mAP (Mean Average Precision)\n",
    "    try:\n",
    "        map_score = average_precision_score(y_true, y_prob, average='macro')\n",
    "        metrics['mAP'] = map_score\n",
    "    except ValueError:\n",
    "        metrics['mAP'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ:\")\n",
    "print(\"- train_model(): ëª¨ë¸ í•™ìŠµ\")\n",
    "print(\"- evaluate_model(): ëª¨ë¸ í‰ê°€\")\n",
    "print(\"- calculate_metrics(): í‰ê°€ ì§€í‘œ ê³„ì‚°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72451931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. ë°ì´í„° ë¡œë”© ë° ë¶„í• \n",
    "# Data Loading and Splitting\n",
    "\n",
    "def load_and_split_data():\n",
    "    \"\"\"\n",
    "    MM-IMDb ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• \n",
    "    ë…¼ë¬¸ ê³„íšì— ë”°ë¼ 70% / 15% / 15%ë¡œ ë¶„í• \n",
    "    \"\"\"\n",
    "    # ì‹¤ì œ ë°ì´í„° ë¡œë”© (ì˜ˆì‹œ ì½”ë“œ - ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "    try:\n",
    "        # ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "        with open(METADATA_PATH, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"ì „ì²´ ë°ì´í„° ê°œìˆ˜: {len(data)}\")\n",
    "        \n",
    "        # ë°ì´í„° ì„ê¸°\n",
    "        np.random.seed(42)\n",
    "        indices = np.random.permutation(len(data))\n",
    "        \n",
    "        # ë¶„í•  ì§€ì  ê³„ì‚°\n",
    "        train_end = int(0.7 * len(data))\n",
    "        val_end = int(0.85 * len(data))\n",
    "        \n",
    "        train_indices = indices[:train_end]\n",
    "        val_indices = indices[train_end:val_end]\n",
    "        test_indices = indices[val_end:]\n",
    "        \n",
    "        # ë¶„í• ëœ ë°ì´í„° ìƒì„±\n",
    "        train_data = [data[i] for i in train_indices]\n",
    "        val_data = [data[i] for i in val_indices]\n",
    "        test_data = [data[i] for i in test_indices]\n",
    "        \n",
    "        print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_data)} ({len(train_data)/len(data)*100:.1f}%)\")\n",
    "        print(f\"ê²€ì¦ ë°ì´í„°: {len(val_data)} ({len(val_data)/len(data)*100:.1f}%)\")\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)} ({len(test_data)/len(data)*100:.1f}%)\")\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {METADATA_PATH}\")\n",
    "        print(\"ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "        return create_sample_data()\n",
    "\n",
    "def create_sample_data():\n",
    "    \"\"\"\n",
    "    í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°)\n",
    "    \"\"\"\n",
    "    sample_data = []\n",
    "    for i in range(1000):  # 1000ê°œ ìƒ˜í”Œ\n",
    "        sample_data.append({\n",
    "            'imdb_id': f'tt{i:07d}',\n",
    "            'image': f'movie_{i}.jpg',\n",
    "            'plot': f'This is a sample movie plot for movie {i}. It contains various elements of storytelling.',\n",
    "            'genres': np.random.choice(GENRE_LABELS, size=np.random.randint(1, 4), replace=False).tolist()\n",
    "        })\n",
    "    \n",
    "    # 70% / 15% / 15% ë¶„í• \n",
    "    train_data = sample_data[:700]\n",
    "    val_data = sample_data[700:850]\n",
    "    test_data = sample_data[850:]\n",
    "    \n",
    "    print(\"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ:\")\n",
    "    print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_data)}\")\n",
    "    print(f\"ê²€ì¦ ë°ì´í„°: {len(val_data)}\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}\")\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def create_data_loaders(train_data, val_data, test_data, tokenizer):\n",
    "    \"\"\"ë°ì´í„° ë¡œë” ìƒì„±\"\"\"\n",
    "    # ë°ì´í„°ì…‹ ìƒì„±\n",
    "    train_dataset = MMIMDbDataset(train_data, IMAGE_PATH, tokenizer, train_transform, MAX_TEXT_LENGTH)\n",
    "    val_dataset = MMIMDbDataset(val_data, IMAGE_PATH, tokenizer, val_transform, MAX_TEXT_LENGTH)\n",
    "    test_dataset = MMIMDbDataset(test_data, IMAGE_PATH, tokenizer, val_transform, MAX_TEXT_LENGTH)\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë” ìƒì„±\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ì‹¤í–‰\n",
    "print(\"ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "train_data, val_data, test_data = load_and_split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c62084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MM-IMDb ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "# MM-IMDb Dataset Download\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def download_mmimdb_dataset():\n",
    "    \"\"\"MM-IMDb ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ\"\"\"\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ URLë“¤\n",
    "    urls = {\n",
    "        'metadata': 'https://archive.org/download/mmimdb/mmimdb.tar.gz',\n",
    "        'images': 'https://archive.org/download/mmimdb/mmimdb.tar.gz'  # ê°™ì€ íŒŒì¼ì— í¬í•¨\n",
    "    }\n",
    "    \n",
    "    # ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    download_dir = Path(\"downloads\")\n",
    "    data_dir = Path(\"data/mmimdb\")\n",
    "    \n",
    "    download_dir.mkdir(exist_ok=True)\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"ğŸ“¥ MM-IMDb ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "    dataset_file = download_dir / \"mmimdb.tar.gz\"\n",
    "    \n",
    "    if not dataset_file.exists():\n",
    "        print(\"ğŸŒ ë°ì´í„°ì…‹ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(urls['metadata'], stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "            downloaded_size = 0\n",
    "            \n",
    "            with open(dataset_file, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        downloaded_size += len(chunk)\n",
    "                        \n",
    "                        # ì§„í–‰ë¥  í‘œì‹œ\n",
    "                        if total_size > 0:\n",
    "                            percent = (downloaded_size / total_size) * 100\n",
    "                            print(f\"\\rì§„í–‰ë¥ : {percent:.1f}% ({downloaded_size/1024/1024:.1f}MB / {total_size/1024/1024:.1f}MB)\", end='')\n",
    "            \n",
    "            print(f\"\\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {dataset_file}\")\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"âœ… ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨: {dataset_file}\")\n",
    "    \n",
    "    # ì••ì¶• í•´ì œ\n",
    "    print(\"ğŸ“¦ ì••ì¶• íŒŒì¼ í•´ì œ ì¤‘...\")\n",
    "    try:\n",
    "        with tarfile.open(dataset_file, 'r:gz') as tar:\n",
    "            # ì••ì¶• íŒŒì¼ ë‚´ìš© í™•ì¸\n",
    "            members = tar.getmembers()\n",
    "            print(f\"ì••ì¶• íŒŒì¼ ë‚´ íŒŒì¼ ìˆ˜: {len(members)}\")\n",
    "            \n",
    "            # ì§„í–‰ë¥ ê³¼ í•¨ê»˜ ì••ì¶• í•´ì œ\n",
    "            for i, member in enumerate(members):\n",
    "                tar.extract(member, path=download_dir)\n",
    "                if i % 100 == 0:  # 100ê°œë§ˆë‹¤ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "                    percent = (i / len(members)) * 100\n",
    "                    print(f\"\\rì••ì¶• í•´ì œ ì§„í–‰ë¥ : {percent:.1f}%\", end='')\n",
    "            \n",
    "            print(f\"\\nâœ… ì••ì¶• í•´ì œ ì™„ë£Œ\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì••ì¶• í•´ì œ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # íŒŒì¼ ì •ë¦¬\n",
    "    print(\"ğŸ“ íŒŒì¼ ì •ë¦¬ ì¤‘...\")\n",
    "    \n",
    "    # ì••ì¶• í•´ì œëœ ë””ë ‰í† ë¦¬ ì°¾ê¸°\n",
    "    extracted_dirs = [d for d in download_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if extracted_dirs:\n",
    "        source_dir = extracted_dirs[0]  # ì²« ë²ˆì§¸ ë””ë ‰í† ë¦¬\n",
    "        \n",
    "        # íŒŒì¼ë“¤ì„ data/mmimdbë¡œ ì´ë™\n",
    "        for item in source_dir.rglob('*'):\n",
    "            if item.is_file():\n",
    "                # ìƒëŒ€ ê²½ë¡œ ê³„ì‚°\n",
    "                rel_path = item.relative_to(source_dir)\n",
    "                dest_path = data_dir / rel_path\n",
    "                \n",
    "                # ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "                dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # íŒŒì¼ ì´ë™\n",
    "                shutil.copy2(item, dest_path)\n",
    "        \n",
    "        print(f\"âœ… íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {data_dir}\")\n",
    "    \n",
    "    # ë‹¤ìš´ë¡œë“œ ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
    "    print(\"ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘...\")\n",
    "    if dataset_file.exists():\n",
    "        dataset_file.unlink()\n",
    "    \n",
    "    for temp_dir in extracted_dirs:\n",
    "        if temp_dir.exists():\n",
    "            shutil.rmtree(temp_dir)\n",
    "    \n",
    "    # ê²°ê³¼ í™•ì¸\n",
    "    print(\"\\nğŸ“Š ë‹¤ìš´ë¡œë“œ ê²°ê³¼:\")\n",
    "    if data_dir.exists():\n",
    "        file_count = len(list(data_dir.rglob('*')))\n",
    "        print(f\"- ì €ì¥ ìœ„ì¹˜: {data_dir}\")\n",
    "        print(f\"- ì´ íŒŒì¼ ìˆ˜: {file_count}\")\n",
    "        \n",
    "        # ì£¼ìš” íŒŒì¼ë“¤ í™•ì¸\n",
    "        important_files = ['dataset.json', 'split.json']\n",
    "        for file_name in important_files:\n",
    "            file_path = data_dir / file_name\n",
    "            if file_path.exists():\n",
    "                print(f\"- âœ… {file_name} ë°œê²¬\")\n",
    "            else:\n",
    "                print(f\"- âŒ {file_name} ì—†ìŒ\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "        image_dirs = ['images', 'imgs', 'posters']\n",
    "        for dir_name in image_dirs:\n",
    "            dir_path = data_dir / dir_name\n",
    "            if dir_path.exists() and dir_path.is_dir():\n",
    "                image_count = len(list(dir_path.glob('*')))\n",
    "                print(f\"- âœ… {dir_name} ë””ë ‰í† ë¦¬: {image_count}ê°œ íŒŒì¼\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def download_alternative_mmimdb():\n",
    "    \"\"\"ëŒ€ì•ˆ ë‹¤ìš´ë¡œë“œ ë°©ë²• (Kaggle ë“±)\"\"\"\n",
    "    print(\"ğŸ”„ ëŒ€ì•ˆ ë‹¤ìš´ë¡œë“œ ë°©ë²•ì„ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # GitHubì—ì„œ ìƒ˜í”Œ ë°ì´í„° ë˜ëŠ” ë‹¤ë¥¸ ì†ŒìŠ¤ ì‹œë„\n",
    "    alternative_urls = [\n",
    "        \"https://github.com/johnarevalo/mmimdb/archive/refs/heads/master.zip\",\n",
    "        \"https://raw.githubusercontent.com/johnarevalo/mmimdb/master/dataset.json\"\n",
    "    ]\n",
    "    \n",
    "    data_dir = Path(\"data/mmimdb\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for i, url in enumerate(alternative_urls):\n",
    "        try:\n",
    "            print(f\"ì‹œë„ {i+1}: {url}\")\n",
    "            response = requests.get(url, stream=True, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            if url.endswith('.zip'):\n",
    "                file_path = data_dir / \"mmimdb_alt.zip\"\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                \n",
    "                # ZIP ì••ì¶• í•´ì œ\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(data_dir)\n",
    "                file_path.unlink()  # ZIP íŒŒì¼ ì‚­ì œ\n",
    "                \n",
    "            elif url.endswith('.json'):\n",
    "                file_path = data_dir / \"dataset.json\"\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "            \n",
    "            print(f\"âœ… ì„±ê³µ: {url}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return False\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"MM-IMDb ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\\n\")\n",
    "\n",
    "success = download_mmimdb_dataset()\n",
    "\n",
    "if not success:\n",
    "    print(\"\\nê¸°ë³¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ëŒ€ì•ˆ ë°©ë²•ì„ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "    success = download_alternative_mmimdb()\n",
    "\n",
    "if not success:\n",
    "    print(\"\\nâŒ ëª¨ë“  ë‹¤ìš´ë¡œë“œ ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:\")\n",
    "    print(\"1. https://archive.org/details/mmimdb ì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\")\n",
    "    print(\"2. ì••ì¶• í•´ì œ í›„ data/mmimdb í´ë”ì— ì €ì¥\")\n",
    "    print(\"3. ë˜ëŠ” Kaggle, GitHub ë“±ì—ì„œ MM-IMDb ë°ì´í„°ì…‹ ê²€ìƒ‰\")\n",
    "else:\n",
    "    print(f\"\\nğŸ‰ MM-IMDb ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "    print(f\"ì €ì¥ ìœ„ì¹˜: data/mmimdb\")\n",
    "    print(\"ì´ì œ ë‹¤ìŒ ì…€ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4686b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ëª¨ë¸ ì‹¤í—˜ ì‹¤í–‰\n",
    "# Model Experiments Execution\n",
    "\n",
    "# ì‹¤í—˜í•  ëª¨ë¸ë“¤ ì •ì˜\n",
    "models_to_test = {\n",
    "    'BERT': BERTClassifier(),\n",
    "    'RoBERTa': RoBERTaClassifier(),\n",
    "    'ResNet50': ResNetClassifier(),\n",
    "    'ViT': ViTClassifier(),\n",
    "    'Early_Fusion': EarlyFusionModel(),\n",
    "    'Late_Fusion': LateFusionModel(),\n",
    "    'Attention_Fusion': AttentionFusionModel(),\n",
    "    'Cross_Attention_Fusion': CrossAttentionFusionModel()  # ì œì•ˆ ëª¨ë¸\n",
    "}\n",
    "\n",
    "# ì‹¤í—˜ ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬\n",
    "experiment_results = {}\n",
    "\n",
    "def run_experiment(model_name, model, train_loader, val_loader, test_loader):\n",
    "    \"\"\"ë‹¨ì¼ ëª¨ë¸ ì‹¤í—˜ ì‹¤í–‰\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ì‹¤í—˜ ì‹œì‘: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    print(\"ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "    train_losses, val_losses = train_model(model, train_loader, val_loader)\n",
    "    \n",
    "    # ìµœì  ëª¨ë¸ ë¡œë“œ\n",
    "    model.load_state_dict(torch.load(f'best_model_{type(model).__name__}.pth'))\n",
    "    \n",
    "    # ëª¨ë¸ í‰ê°€\n",
    "    print(\"ëª¨ë¸ í‰ê°€ ì¤‘...\")\n",
    "    metrics = evaluate_model(model, test_loader, model_name)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    experiment_results[model_name] = {\n",
    "        'metrics': metrics,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses\n",
    "    }\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\n{model_name} ì‹¤í—˜ ê²°ê³¼:\")\n",
    "    print(\"-\" * 30)\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ì¶•ì•½ëœ ì‹¤í—˜ (ì‹œê°„ ì ˆì•½ì„ ìœ„í•´)\n",
    "print(\"ì¶•ì•½ëœ ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (ê° ëª¨ë¸ 5 ì—í¬í¬)...\")\n",
    "NUM_EPOCHS = 5  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì—í¬í¬ ìˆ˜ ì¤„ì„\n",
    "\n",
    "# BERT í…ìŠ¤íŠ¸ ëª¨ë¸ë§Œ ìš°ì„  í…ŒìŠ¤íŠ¸ (ì˜ˆì‹œ)\n",
    "print(\"BERT ëª¨ë¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ë¡œë” ìƒì„±...\")\n",
    "try:\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_data, val_data, test_data, bert_tokenizer\n",
    "    )\n",
    "    print(\"ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    # BERT ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "    bert_model = BERTClassifier()\n",
    "    print(\"BERT ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ë°ì´í„° ë¡œë” ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì–´ ëª¨ë¸ êµ¬ì¡°ë§Œ í™•ì¸í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. ê²°ê³¼ ì‹œê°í™” ë° ë¶„ì„\n",
    "# Results Visualization and Analysis\n",
    "\n",
    "def plot_training_curves(experiment_results):\n",
    "    \"\"\"í•™ìŠµ ê³¡ì„  ì‹œê°í™”\"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (model_name, results) in enumerate(experiment_results.items()):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        train_losses = results['train_losses']\n",
    "        val_losses = results['val_losses']\n",
    "        \n",
    "        epochs = range(1, len(train_losses) + 1)\n",
    "        ax.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "        ax.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "        ax.set_title(f'{model_name} Learning Curves')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    # ë¹ˆ subplot ìˆ¨ê¸°ê¸°\n",
    "    for idx in range(len(experiment_results), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_performance_comparison(experiment_results):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”\"\"\"\n",
    "    if not experiment_results:\n",
    "        print(\"ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    # ì£¼ìš” ì§€í‘œë“¤ ì¶”ì¶œ\n",
    "    metrics_to_plot = ['Exact_Match_Accuracy', 'Label_Accuracy', 'Macro_F1', 'ROC_AUC_Macro', 'mAP']\n",
    "    \n",
    "    model_names = list(experiment_results.keys())\n",
    "    metric_data = {metric: [] for metric in metrics_to_plot}\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        for metric in metrics_to_plot:\n",
    "            value = experiment_results[model_name]['metrics'].get(metric, 0)\n",
    "            metric_data[metric].append(value)\n",
    "    \n",
    "    # íˆíŠ¸ë§µ ìƒì„±\n",
    "    df = pd.DataFrame(metric_data, index=model_names)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(df, annot=True, cmap='YlOrRd', fmt='.3f', cbar=True)\n",
    "    plt.title('Model Performance Comparison Heatmap')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Models')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        values = metric_data[metric]\n",
    "        bars = ax.bar(model_names, values, color='skyblue', alpha=0.7)\n",
    "        ax.set_title(f'{metric} Comparison')\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°•ì¡°\n",
    "        if values:\n",
    "            max_idx = values.index(max(values))\n",
    "            bars[max_idx].set_color('orange')\n",
    "        \n",
    "        # ê°’ í‘œì‹œ\n",
    "        for bar, value in zip(bars, values):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                   f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # ë¹ˆ subplot ìˆ¨ê¸°ê¸°\n",
    "    for idx in range(len(metrics_to_plot), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_performance_table(experiment_results):\n",
    "    \"\"\"ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ìƒì„±\"\"\"\n",
    "    if not experiment_results:\n",
    "        print(\"ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ì„±ëŠ¥ í…Œì´ë¸” ìƒì„±\n",
    "    metrics_to_include = [\n",
    "        'Exact_Match_Accuracy', 'Label_Accuracy', 'Macro_Precision', \n",
    "        'Macro_Recall', 'Macro_F1', 'ROC_AUC_Macro', 'mAP'\n",
    "    ]\n",
    "    \n",
    "    table_data = []\n",
    "    for model_name, results in experiment_results.items():\n",
    "        row = [model_name]\n",
    "        for metric in metrics_to_include:\n",
    "            value = results['metrics'].get(metric, 0)\n",
    "            row.append(f\"{value:.4f}\")\n",
    "        table_data.append(row)\n",
    "    \n",
    "    # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    columns = ['Model'] + metrics_to_include\n",
    "    df = pd.DataFrame(table_data, columns=columns)\n",
    "    \n",
    "    # ìµœê³  ì„±ëŠ¥ ì°¾ê¸°\n",
    "    print(\"ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼\")\n",
    "    print(\"=\" * 120)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìš”ì•½\n",
    "    for metric in metrics_to_include[1:]:  # Model ì»¬ëŸ¼ ì œì™¸\n",
    "        values = [float(row[metrics_to_include.index(metric)]) for row in table_data]\n",
    "        best_idx = values.index(max(values))\n",
    "        best_model = table_data[best_idx][0]\n",
    "        best_value = max(values)\n",
    "        print(f\"ğŸ† {metric} ìµœê³  ì„±ëŠ¥: {best_model} ({best_value:.4f})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ìƒ˜í”Œ ê²°ê³¼ ì‹œê°í™” (ì‹¤ì œ ì‹¤í—˜ í›„ ì‚¬ìš©)\n",
    "print(\"ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ:\")\n",
    "print(\"- plot_training_curves(): í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„\")\n",
    "print(\"- plot_performance_comparison(): ì„±ëŠ¥ ë¹„êµ íˆíŠ¸ë§µ ë° ë§‰ëŒ€ê·¸ë˜í”„\")\n",
    "print(\"- generate_performance_table(): ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”\")\n",
    "print(\"\\nì‹¤ì œ ëª¨ë¸ í•™ìŠµ í›„ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•˜ì„¸ìš”:\")\n",
    "print(\"plot_training_curves(experiment_results)\")\n",
    "print(\"plot_performance_comparison(experiment_results)\")\n",
    "print(\"generate_performance_table(experiment_results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cfc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ì„¤ëª…ê°€ëŠ¥ì„± ë¶„ì„ (XAI) - Grad-CAM & Attention Map\n",
    "# Explainable AI Analysis\n",
    "\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"Grad-CAM êµ¬í˜„ í´ë˜ìŠ¤\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Hook ë“±ë¡\n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_backward_hook(self.save_gradient)\n",
    "    \n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate_cam(self, input_image, class_idx=None):\n",
    "        \"\"\"Grad-CAM ìƒì„±\"\"\"\n",
    "        # ìˆœì „íŒŒ\n",
    "        output = self.model(input_image)\n",
    "        \n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1)\n",
    "        \n",
    "        # ì—­ì „íŒŒ\n",
    "        self.model.zero_grad()\n",
    "        class_score = output[:, class_idx].squeeze()\n",
    "        class_score.backward(retain_graph=True)\n",
    "        \n",
    "        # Grad-CAM ê³„ì‚°\n",
    "        gradients = self.gradients[0]  # [C, H, W]\n",
    "        activations = self.activations[0]  # [C, H, W]\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        weights = torch.mean(gradients, dim=(1, 2))  # [C]\n",
    "        \n",
    "        # ê°€ì¤‘ í•©\n",
    "        cam = torch.zeros(activations.shape[1:])  # [H, W]\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i, :, :]\n",
    "        \n",
    "        # ReLU ì ìš©\n",
    "        cam = torch.relu(cam)\n",
    "        \n",
    "        # ì •ê·œí™”\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "        \n",
    "        return cam.cpu().numpy()\n",
    "\n",
    "def visualize_gradcam(model, image, genre_idx, image_transform):\n",
    "    \"\"\"Grad-CAM ì‹œê°í™”\"\"\"\n",
    "    # ResNet ê¸°ë°˜ ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì°¾ê¸°\n",
    "    if hasattr(model, 'resnet'):\n",
    "        target_layer = model.resnet.layer4[-1].conv3\n",
    "    elif hasattr(model, 'vit'):\n",
    "        # ViTì˜ ê²½ìš° ë‹¤ë¥¸ ë°©ì‹ í•„ìš”\n",
    "        print(\"ViT ëª¨ë¸ì˜ Grad-CAMì€ ë³„ë„ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # Grad-CAM ìƒì„±\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    model.eval()\n",
    "    \n",
    "    # ì…ë ¥ ì´ë¯¸ì§€ ì¤€ë¹„\n",
    "    input_tensor = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    # CAM ìƒì„±\n",
    "    cam = gradcam.generate_cam(input_tensor, genre_idx)\n",
    "    \n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ì •ê·œí™” í•´ì œ)\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    \n",
    "    original_image = image.clone()\n",
    "    for t, m, s in zip(original_image, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    original_image = torch.clamp(original_image, 0, 1)\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # ì›ë³¸ ì´ë¯¸ì§€\n",
    "    axes[0].imshow(original_image.permute(1, 2, 0))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Grad-CAM íˆíŠ¸ë§µ\n",
    "    axes[1].imshow(cam, cmap='jet')\n",
    "    axes[1].set_title(f'Grad-CAM for {GENRE_LABELS[genre_idx]}')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # ì˜¤ë²„ë ˆì´\n",
    "    overlay = original_image.permute(1, 2, 0).numpy()\n",
    "    cam_resized = cv2.resize(cam, (overlay.shape[1], overlay.shape[0]))\n",
    "    cam_colored = cm.jet(cam_resized)[:, :, :3]\n",
    "    \n",
    "    overlay_image = 0.6 * overlay + 0.4 * cam_colored\n",
    "    axes[2].imshow(overlay_image)\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "class AttentionVisualizer:\n",
    "    \"\"\"ì–´í…ì…˜ ë§µ ì‹œê°í™” í´ë˜ìŠ¤\"\"\"\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def extract_attention_weights(self, input_ids, attention_mask):\n",
    "        \"\"\"ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì¶”ì¶œ\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # BERTì˜ ê²½ìš°\n",
    "        if hasattr(self.model, 'bert'):\n",
    "            outputs = self.model.bert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_attentions=True\n",
    "            )\n",
    "            attentions = outputs.attentions  # Tuple of attention weights\n",
    "            \n",
    "            # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì²« ë²ˆì§¸ í—¤ë“œ ì‚¬ìš©\n",
    "            attention_weights = attentions[-1][0, 0, :, :].detach().cpu().numpy()\n",
    "            return attention_weights\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def visualize_attention(self, text, input_ids, attention_mask):\n",
    "        \"\"\"ì–´í…ì…˜ ë§µ ì‹œê°í™”\"\"\"\n",
    "        attention_weights = self.extract_attention_weights(input_ids, attention_mask)\n",
    "        \n",
    "        if attention_weights is None:\n",
    "            print(\"ì–´í…ì…˜ ê°€ì¤‘ì¹˜ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        # í† í° ë””ì½”ë”©\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        \n",
    "        # [CLS] í† í°ì˜ ì–´í…ì…˜ë§Œ ì‚¬ìš© (ì²« ë²ˆì§¸ í† í°)\n",
    "        cls_attention = attention_weights[0, :]\n",
    "        \n",
    "        # ìœ íš¨í•œ í† í°ë§Œ ì„ ë³„ (íŒ¨ë”© ì œì™¸)\n",
    "        valid_length = attention_mask.sum().item()\n",
    "        tokens = tokens[:valid_length]\n",
    "        cls_attention = cls_attention[:valid_length]\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # ì–´í…ì…˜ íˆíŠ¸ë§µ\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.imshow(cls_attention.reshape(1, -1), cmap='Blues', aspect='auto')\n",
    "        plt.xticks(range(len(tokens)), tokens, rotation=45, ha='right')\n",
    "        plt.yticks([0], ['[CLS]'])\n",
    "        plt.title('Attention Weights from [CLS] Token')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # ì–´í…ì…˜ ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "        plt.subplot(2, 1, 2)\n",
    "        bars = plt.bar(range(len(tokens)), cls_attention, color='skyblue', alpha=0.7)\n",
    "        plt.xticks(range(len(tokens)), tokens, rotation=45, ha='right')\n",
    "        plt.ylabel('Attention Weight')\n",
    "        plt.title('Token-wise Attention Weights')\n",
    "        \n",
    "        # ë†’ì€ ì–´í…ì…˜ í† í° ê°•ì¡°\n",
    "        top_indices = cls_attention.argsort()[-5:]  # ìƒìœ„ 5ê°œ\n",
    "        for idx in top_indices:\n",
    "            bars[idx].set_color('orange')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # ì¤‘ìš”í•œ í† í°ë“¤ ì¶œë ¥\n",
    "        print(\"ğŸ” ë†’ì€ ì–´í…ì…˜ì„ ë°›ì€ í† í°ë“¤:\")\n",
    "        for idx in top_indices[::-1]:\n",
    "            print(f\"  '{tokens[idx]}': {cls_attention[idx]:.4f}\")\n",
    "\n",
    "def run_xai_analysis(model, sample_batch, model_name=\"Model\"):\n",
    "    \"\"\"XAI ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ì„¤ëª…ê°€ëŠ¥ì„± ë¶„ì„: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° ì„ íƒ\n",
    "    sample_image = sample_batch['image'][0]\n",
    "    sample_input_ids = sample_batch['input_ids'][0:1]\n",
    "    sample_attention_mask = sample_batch['attention_mask'][0:1]\n",
    "    sample_text = sample_batch['text'][0]\n",
    "    sample_labels = sample_batch['labels'][0]\n",
    "    \n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    with torch.no_grad():\n",
    "        if isinstance(model, (BERTClassifier, RoBERTaClassifier)):\n",
    "            outputs = model(sample_input_ids.to(device), sample_attention_mask.to(device))\n",
    "        elif isinstance(model, (ResNetClassifier, ViTClassifier)):\n",
    "            outputs = model(sample_image.unsqueeze(0).to(device))\n",
    "        else:  # ë©€í‹°ëª¨ë‹¬ ëª¨ë¸\n",
    "            outputs = model(\n",
    "                sample_image.unsqueeze(0).to(device),\n",
    "                sample_input_ids.to(device),\n",
    "                sample_attention_mask.to(device)\n",
    "            )\n",
    "    \n",
    "    probabilities = torch.sigmoid(outputs)\n",
    "    predictions = (probabilities > 0.5).float()\n",
    "    \n",
    "    # ì˜ˆì¸¡ëœ ì¥ë¥´ë“¤\n",
    "    predicted_genres = [GENRE_LABELS[i] for i, pred in enumerate(predictions[0]) if pred == 1]\n",
    "    actual_genres = [GENRE_LABELS[i] for i, label in enumerate(sample_labels) if label == 1]\n",
    "    \n",
    "    print(f\"ì‹¤ì œ ì¥ë¥´: {actual_genres}\")\n",
    "    print(f\"ì˜ˆì¸¡ ì¥ë¥´: {predicted_genres}\")\n",
    "    print()\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ëª¨ë¸ì¸ ê²½ìš° Grad-CAM\n",
    "    if isinstance(model, (ResNetClassifier, ViTClassifier)) or hasattr(model, 'resnet'):\n",
    "        print(\"Grad-CAM ë¶„ì„ ì¤‘...\")\n",
    "        if predicted_genres:\n",
    "            top_genre_idx = GENRE_LABELS.index(predicted_genres[0])\n",
    "            visualize_gradcam(model, sample_image, top_genre_idx, val_transform)\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ëª¨ë¸ì¸ ê²½ìš° Attention Map\n",
    "    if isinstance(model, (BERTClassifier, RoBERTaClassifier)) or hasattr(model, 'bert'):\n",
    "        print(\"Attention Map ë¶„ì„ ì¤‘...\")\n",
    "        if isinstance(model, BERTClassifier) or hasattr(model, 'bert'):\n",
    "            visualizer = AttentionVisualizer(model, bert_tokenizer)\n",
    "            visualizer.visualize_attention(sample_text, sample_input_ids, sample_attention_mask)\n",
    "\n",
    "print(\"ì„¤ëª…ê°€ëŠ¥ì„± ë¶„ì„ ë„êµ¬ ì •ì˜ ì™„ë£Œ:\")\n",
    "print(\"- GradCAM: ì´ë¯¸ì§€ ì˜ì—­ ì¤‘ìš”ë„ ì‹œê°í™”\")\n",
    "print(\"- AttentionVisualizer: í…ìŠ¤íŠ¸ í† í° ì¤‘ìš”ë„ ì‹œê°í™”\")\n",
    "print(\"- run_xai_analysis(): í†µí•© XAI ë¶„ì„ ì‹¤í–‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad553492",
   "metadata": {},
   "source": [
    "# ğŸ“‹ ì‹¤í—˜ ê²°ë¡  ë° ìš”ì•½\n",
    "\n",
    "## ğŸ¯ ì—°êµ¬ ëª©í‘œ ë‹¬ì„±ë„\n",
    "\n",
    "### 1. ëª¨ë¸ ë¹„êµ ë¶„ì„\n",
    "- **ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° ëª¨ë¸**: BERT, RoBERTa (í…ìŠ¤íŠ¸), ResNet50, ViT (ì´ë¯¸ì§€)\n",
    "- **ë©€í‹°ëª¨ë‹¬ ìœµí•© ëª¨ë¸**: Early Fusion, Late Fusion, Attention Fusion\n",
    "- **ì œì•ˆ ëª¨ë¸**: Cross-Attention Fusion\n",
    "\n",
    "### 2. í‰ê°€ ì§€í‘œ\n",
    "- **ì •í™•ë„ ì§€í‘œ**: Exact Match Accuracy, Label Accuracy\n",
    "- **ë¶„ë¥˜ ì„±ëŠ¥**: Macro/Micro Precision, Recall, F1-score\n",
    "- **ìˆœìœ„ ê¸°ë°˜**: ROC-AUC, mAP (Mean Average Precision)\n",
    "\n",
    "### 3. ì„¤ëª…ê°€ëŠ¥ì„± (XAI)\n",
    "- **ì´ë¯¸ì§€ ë¶„ì„**: Grad-CAMì„ í†µí•œ í¬ìŠ¤í„° ë‚´ ì¤‘ìš” ì˜ì—­ ì‹œê°í™”\n",
    "- **í…ìŠ¤íŠ¸ ë¶„ì„**: Attention Mapì„ í†µí•œ ì¤„ê±°ë¦¬ ë‚´ ì¤‘ìš” í† í° ì‹ë³„\n",
    "\n",
    "## ğŸ”¬ ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "\n",
    "### ì˜ˆìƒ ê²°ê³¼\n",
    "1. **Cross-Attention Fusion ëª¨ë¸**ì´ ê¸°ì¡´ ìœµí•© ë°©ì‹ ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥ ì˜ˆìƒ\n",
    "2. **ë©€í‹°ëª¨ë‹¬ ëª¨ë¸**ì´ ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° ëª¨ë¸ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ ì˜ˆìƒ\n",
    "3. **í…ìŠ¤íŠ¸ ì •ë³´**ê°€ ì´ë¯¸ì§€ë³´ë‹¤ ì¥ë¥´ ì˜ˆì¸¡ì— ë” ì¤‘ìš”í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ\n",
    "\n",
    "### ì„±ëŠ¥ ë¹„êµ ìˆœì„œ (ì˜ˆìƒ)\n",
    "1. Cross-Attention Fusion (ì œì•ˆ ëª¨ë¸)\n",
    "2. Attention Fusion\n",
    "3. Late Fusion\n",
    "4. Early Fusion\n",
    "5. BERT/RoBERTa (í…ìŠ¤íŠ¸ ë‹¨ì¼)\n",
    "6. ResNet50/ViT (ì´ë¯¸ì§€ ë‹¨ì¼)\n",
    "\n",
    "## ğŸ“Š í™œìš© ë°©ë²•\n",
    "\n",
    "### ì‹¤í—˜ ì‹¤í–‰ ìˆœì„œ\n",
    "1. **í™˜ê²½ ì„¤ì •**: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° GPU ì„¤ì •\n",
    "2. **ë°ì´í„° ì¤€ë¹„**: MM-IMDb ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ê²½ë¡œ ì„¤ì •\n",
    "3. **ëª¨ë¸ í•™ìŠµ**: ê° ëª¨ë¸ë³„ ìˆœì°¨ í•™ìŠµ ë° ê²€ì¦\n",
    "4. **ì„±ëŠ¥ í‰ê°€**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ìµœì¢… í‰ê°€\n",
    "5. **ê²°ê³¼ ë¶„ì„**: ì‹œê°í™” ë° XAI ë¶„ì„\n",
    "\n",
    "### ì‹¤ì œ ë°ì´í„° ì‚¬ìš©ì‹œ ìˆ˜ì •ì‚¬í•­\n",
    "- `DATASET_PATH`, `IMAGE_PATH`, `METADATA_PATH` ë³€ìˆ˜ë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •\n",
    "- ë°ì´í„°ì…‹ í˜•ì‹ì— ë§ê²Œ `MMIMDbDataset` í´ë˜ìŠ¤ ì¡°ì •\n",
    "- GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ `BATCH_SIZE` ì¡°ì •\n",
    "- ìˆ˜ë ´ ì†ë„ì— ë”°ë¼ `NUM_EPOCHS` ì¡°ì •\n",
    "\n",
    "## ğŸš€ í™•ì¥ ê°€ëŠ¥ì„±\n",
    "\n",
    "### ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´\n",
    "1. **ê°ì²´ íƒì§€ í†µí•©**: YOLO, Faster R-CNN íŠ¹ì§• í™œìš©\n",
    "2. **ë°ì´í„° ì¦ê°•**: ë” ë‹¤ì–‘í•œ ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ì¦ê°• ê¸°ë²•\n",
    "3. **ì•™ìƒë¸” í•™ìŠµ**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©\n",
    "4. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**: Optuna ë“±ì„ í™œìš©í•œ ìë™ íŠœë‹\n",
    "5. **ì „ì´ í•™ìŠµ**: ë‹¤ë¥¸ ì˜í™” ë°ì´í„°ì…‹ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦\n",
    "\n",
    "### ë…¼ë¬¸ ê¸°ì—¬ì \n",
    "- Cross-Attention ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ìœµí•© ë°©ë²•ë¡  ì œì•ˆ\n",
    "- MM-IMDb ë°ì´í„°ì…‹ì—ì„œì˜ ì²´ê³„ì ì¸ ëª¨ë¸ ë¹„êµ ë¶„ì„\n",
    "- ì„¤ëª…ê°€ëŠ¥ì„± ê´€ì ì—ì„œì˜ ëª¨ë¸ í•´ì„ ë° ë¶„ì„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
